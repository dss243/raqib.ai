{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64096f97",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T17:32:41.496867Z",
     "iopub.status.busy": "2025-04-12T17:32:41.496613Z",
     "iopub.status.idle": "2025-04-12T17:32:58.013945Z",
     "shell.execute_reply": "2025-04-12T17:32:58.012958Z"
    },
    "papermill": {
     "duration": 16.525784,
     "end_time": "2025-04-12T17:32:58.015410",
     "exception": false,
     "start_time": "2025-04-12T17:32:41.489626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d23b9918eb4e3f92a139812fab58b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/381 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d1455961014527bb506efc67773b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf6768361934894892da2aac1c19cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/825k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad12d234ddf42b8b21649d2decf7f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1e054e281240f1b7d14c55a8e60d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 10714 échantillons\n",
      "Validation : 1339 échantillons\n",
      "Test : 1340 échantillons\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Charger les données\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"  # Mets le bon chemin si nécessaire\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir les labels en 0 et 1\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Séparer en train (80%) et test (20%)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "# Séparer temp en validation (10%) et test (10%)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# Charger le tokenizer d'AraBERT\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization des textes avec padding et truncation\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Vérifier la taille des ensembles\n",
    "print(f\"Train : {len(train_texts)} échantillons\")\n",
    "print(f\"Validation : {len(val_texts)} échantillons\")\n",
    "print(f\"Test : {len(test_texts)} échantillons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccabf84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:32:58.028385Z",
     "iopub.status.busy": "2025-04-12T17:32:58.027946Z",
     "iopub.status.idle": "2025-04-12T17:33:05.829190Z",
     "shell.execute_reply": "2025-04-12T17:33:05.828279Z"
    },
    "papermill": {
     "duration": 7.809109,
     "end_time": "2025-04-12T17:33:05.830950",
     "exception": false,
     "start_time": "2025-04-12T17:32:58.021841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting farasapy\r\n",
      "  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\r\n",
      "Collecting arabert\r\n",
      "  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.67.1)\r\n",
      "Requirement already satisfied: PyArabic in /usr/local/lib/python3.10/dist-packages (from arabert) (0.6.15)\r\n",
      "Collecting emoji==1.4.2 (from arabert)\r\n",
      "  Downloading emoji-1.4.2.tar.gz (184 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->arabert) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2025.1.31)\r\n",
      "Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\r\n",
      "Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\r\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186455 sha256=5d9ea76e25fcf65b9558ae85ad929749cc73a776bf70b53ae97dff72009ef09f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\r\n",
      "Successfully built emoji\r\n",
      "Installing collected packages: emoji, farasapy, arabert\r\n",
      "  Attempting uninstall: emoji\r\n",
      "    Found existing installation: emoji 2.14.1\r\n",
      "    Uninstalling emoji-2.14.1:\r\n",
      "      Successfully uninstalled emoji-2.14.1\r\n",
      "Successfully installed arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\r\n"
     ]
    }
   ],
   "source": [
    "!pip install farasapy arabert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9903fa16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:33:05.844236Z",
     "iopub.status.busy": "2025-04-12T17:33:05.843954Z",
     "iopub.status.idle": "2025-04-12T17:33:05.852024Z",
     "shell.execute_reply": "2025-04-12T17:33:05.851057Z"
    },
    "papermill": {
     "duration": 0.01593,
     "end_time": "2025-04-12T17:33:05.853228",
     "exception": false,
     "start_time": "2025-04-12T17:33:05.837298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille train_loader : 670 batches\n",
      "Taille val_loader : 84 batches\n",
      "Taille test_loader : 84 batches\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Définir une classe Dataset pour PyTorch\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "# Créer les datasets\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels)\n",
    "\n",
    "# Définir les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Vérifier la taille des DataLoaders\n",
    "print(f\"Taille train_loader : {len(train_loader)} batches\")\n",
    "print(f\"Taille val_loader : {len(val_loader)} batches\")\n",
    "print(f\"Taille test_loader : {len(test_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c71f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:33:05.865716Z",
     "iopub.status.busy": "2025-04-12T17:33:05.865466Z",
     "iopub.status.idle": "2025-04-12T17:43:06.741823Z",
     "shell.execute_reply": "2025-04-12T17:43:06.740741Z"
    },
    "papermill": {
     "duration": 600.884482,
     "end_time": "2025-04-12T17:43:06.743438",
     "exception": false,
     "start_time": "2025-04-12T17:33:05.858956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e55867f98e48a6a1953a05baf66845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1/3\n",
      "Train Loss: 0.5682 | Train Acc: 0.6962\n",
      "Val Loss: 0.5479 | Val Acc: 0.7334\n",
      "--------------------------------------------------\n",
      "Époque 2/3\n",
      "Train Loss: 0.4409 | Train Acc: 0.7947\n",
      "Val Loss: 0.5522 | Val Acc: 0.7431\n",
      "--------------------------------------------------\n",
      "Époque 3/3\n",
      "Train Loss: 0.3242 | Train Acc: 0.8628\n",
      "Val Loss: 0.5638 | Val Acc: 0.7588\n",
      "--------------------------------------------------\n",
      "Modèle sauvegardé ! ✅\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
    "\n",
    "# Vérifier si GPU disponible\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"GPU\")\n",
    "print(f\"Utilisation de {device}\")\n",
    "\n",
    "# Charger AraBERT pour la classification binaire\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"aubmindlab/bert-base-arabertv02\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Définir l'optimiseur et la fonction de perte\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Scheduler pour ajuster le taux d'apprentissage\n",
    "num_training_steps = len(train_loader) * 3  # 3 époques\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train_epoch(model, train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.logits.argmax(1) == batch[\"labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader), correct / len(train_dataset)\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(**batch)\n",
    "            loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.logits.argmax(1) == batch[\"labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct / len(val_dataset)\n",
    "\n",
    "# Entraînement du modèle\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Époque {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Sauvegarder le modèle entraîné\n",
    "torch.save(model.state_dict(), \"arabert_hate_speech.pth\")\n",
    "print(\"Modèle sauvegardé ! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a04a2",
   "metadata": {
    "papermill": {
     "duration": 0.006521,
     "end_time": "2025-04-12T17:43:06.756579",
     "exception": false,
     "start_time": "2025-04-12T17:43:06.750058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806071dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:43:06.771184Z",
     "iopub.status.busy": "2025-04-12T17:43:06.770502Z",
     "iopub.status.idle": "2025-04-12T17:43:08.093777Z",
     "shell.execute_reply": "2025-04-12T17:43:08.092681Z"
    },
    "papermill": {
     "duration": 1.332384,
     "end_time": "2025-04-12T17:43:08.095452",
     "exception": false,
     "start_time": "2025-04-12T17:43:06.763068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-5-516ed19d4150>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"arabert_hate_speech.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: لن تجد أي خير في هؤلاء، فهذه عقلية موروثة عن أجدادهم. -> Prediction: Hate Speech\n",
      "Text: ما كاين حتى فرق بين الشاوي، القبائلي، المزابيي، ولا التارقي، كلنا خاوة -> Prediction: Not Hate Speech\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define the model name (same as used during training)\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model architecture (must match the one used during training)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Adjust num_labels if needed\n",
    "\n",
    "# Load saved weights\n",
    "model.load_state_dict(torch.load(\"arabert_hate_speech.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def predict(text):\n",
    "    \"\"\"Function to test the model on new input text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return \"Hate Speech\" if predicted_class == 1 else \"Not Hate Speech\"\n",
    "\n",
    "# Example Test Cases\n",
    "test_sentences = [\n",
    "     \"لن تجد أي خير في هؤلاء، فهذه عقلية موروثة عن أجدادهم.\",  # Should return \"Not Hate Speech\"\n",
    "     \"ما كاين حتى فرق بين الشاوي، القبائلي، المزابيي، ولا التارقي، كلنا خاوة\",  # Should return \"Hate Speech\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(f\"Text: {sentence} -> Prediction: {predict(sentence)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d54ca02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:43:08.109719Z",
     "iopub.status.busy": "2025-04-12T17:43:08.109444Z",
     "iopub.status.idle": "2025-04-12T17:53:19.028146Z",
     "shell.execute_reply": "2025-04-12T17:53:19.027161Z"
    },
    "papermill": {
     "duration": 610.927446,
     "end_time": "2025-04-12T17:53:19.029631",
     "exception": false,
     "start_time": "2025-04-12T17:43:08.102185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 1.7574 | Hate Speech Acc: 0.7053 | Topic Acc: 0.6173\n",
      "Val Loss: 1.3887 | Hate Speech Acc: 0.7192 | Topic Acc: 0.7237\n",
      "--------------------------------------------------\n",
      "Epoch 2/3\n",
      "Train Loss: 1.1201 | Hate Speech Acc: 0.7871 | Topic Acc: 0.7869\n",
      "Val Loss: 1.2686 | Hate Speech Acc: 0.7356 | Topic Acc: 0.7453\n",
      "--------------------------------------------------\n",
      "Epoch 3/3\n",
      "Train Loss: 0.8338 | Hate Speech Acc: 0.8343 | Topic Acc: 0.8566\n",
      "Val Loss: 1.2762 | Hate Speech Acc: 0.7431 | Topic Acc: 0.7633\n",
      "--------------------------------------------------\n",
      "Model saved! ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"  # Change this if necessary\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert labels to numeric values\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Encode topics as numbers (Label Encoding)\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# Split into train (80%), validation (10%), and test (10%)\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Tokenization\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize text with truncation and padding\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Custom Dataset Class\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, hate_speech_labels, topic_labels):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels\n",
    "        self.topic_labels = topic_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}  # Fix warning\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels.iloc[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ Define Model\n",
    "# =======================\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hate_speech_classifier = nn.Linear(self.bert.config.hidden_size, 2)  # Hate speech (binary)\n",
    "        self.topic_classifier = nn.Linear(self.bert.config.hidden_size, num_topics)  # Topic classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, hate_speech_labels=None, topic_labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
    "\n",
    "        hate_speech_logits = self.hate_speech_classifier(pooled_output)\n",
    "        topic_logits = self.topic_classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if hate_speech_labels is not None and topic_labels is not None:\n",
    "            hate_speech_loss = nn.CrossEntropyLoss()(hate_speech_logits, hate_speech_labels)\n",
    "            topic_loss = nn.CrossEntropyLoss()(topic_logits, topic_labels)\n",
    "            loss = hate_speech_loss + topic_loss  # Combined loss\n",
    "\n",
    "        return loss, hate_speech_logits, topic_logits\n",
    "\n",
    "# Load Model\n",
    "num_topics = len(topics)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskModel(model_name, num_topics).to(device)\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Training Setup\n",
    "# =======================\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Training and Evaluation\n",
    "# =======================\n",
    "def train_epoch(model, train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct_hate_speech, correct_topic = 0, 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, hate_speech_logits, topic_logits = model(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct_hate_speech += (hate_speech_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "        correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader), correct_hate_speech / len(train_dataset), correct_topic / len(train_dataset)\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss, correct_hate_speech, correct_topic = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, hate_speech_logits, topic_logits = model(**batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_hate_speech += (hate_speech_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "            correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct_hate_speech / len(val_dataset), correct_topic / len(val_dataset)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Train Model\n",
    "# =======================\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc_hate, train_acc_topic = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc_hate, val_acc_topic = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Hate Speech Acc: {train_acc_hate:.4f} | Topic Acc: {train_acc_topic:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Speech Acc: {val_acc_hate:.4f} | Topic Acc: {val_acc_topic:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# =======================\n",
    "# 8️⃣ Save Model\n",
    "# =======================\n",
    "from datetime import datetime\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define filename with timestamp\n",
    "model_path = f\"/kaggle/working/arabert_hate_speech_topics_{timestamp}.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Model saved! ✅\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cb96c",
   "metadata": {
    "papermill": {
     "duration": 0.006331,
     "end_time": "2025-04-12T17:53:19.042887",
     "exception": false,
     "start_time": "2025-04-12T17:53:19.036556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a2ba4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:53:19.057292Z",
     "iopub.status.busy": "2025-04-12T17:53:19.057003Z",
     "iopub.status.idle": "2025-04-12T18:06:22.043797Z",
     "shell.execute_reply": "2025-04-12T18:06:22.042711Z"
    },
    "papermill": {
     "duration": 782.995985,
     "end_time": "2025-04-12T18:06:22.045414",
     "exception": false,
     "start_time": "2025-04-12T17:53:19.049429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 1.7273 | Hate Speech Acc: 0.7049 | Topic Acc: 0.6295\n",
      "Val Loss: 1.3833 | Hate Speech Acc: 0.7162 | Topic Acc: 0.7222\n",
      "--------------------------------------------------\n",
      "Epoch 2/3\n",
      "Train Loss: 1.1088 | Hate Speech Acc: 0.7877 | Topic Acc: 0.7867\n",
      "Val Loss: 1.2632 | Hate Speech Acc: 0.7476 | Topic Acc: 0.7625\n",
      "--------------------------------------------------\n",
      "Epoch 3/3\n",
      "Train Loss: 0.8328 | Hate Speech Acc: 0.8348 | Topic Acc: 0.8569\n",
      "Val Loss: 1.2671 | Hate Speech Acc: 0.7438 | Topic Acc: 0.7647\n",
      "--------------------------------------------------\n",
      "Model saved! ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert labels to numeric values\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Encode topics as numbers\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# Split data\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics,\n",
    "    test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Tokenizer\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Dataset Class (with on-the-fly tokenization ✅)\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, hate_speech_labels, topic_labels, tokenizer, max_length=128):\n",
    "        self.texts = texts.tolist()\n",
    "        self.hate_speech_labels = hate_speech_labels.tolist()\n",
    "        self.topic_labels = topic_labels.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Remove batch dimension\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ DataLoaders\n",
    "# =======================\n",
    "train_dataset = HateSpeechDataset(train_texts, train_labels, train_topics, tokenizer)\n",
    "val_dataset = HateSpeechDataset(val_texts, val_labels, val_topics, tokenizer)\n",
    "test_dataset = HateSpeechDataset(test_texts, test_labels, test_topics, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Model Definition\n",
    "# =======================\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hate_speech_classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.topic_classifier = nn.Linear(self.bert.config.hidden_size, num_topics)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, hate_speech_labels=None, topic_labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        hate_speech_logits = self.hate_speech_classifier(pooled_output)\n",
    "        topic_logits = self.topic_classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if hate_speech_labels is not None and topic_labels is not None:\n",
    "            hate_speech_loss = nn.CrossEntropyLoss()(hate_speech_logits, hate_speech_labels)\n",
    "            topic_loss = nn.CrossEntropyLoss()(topic_logits, topic_labels)\n",
    "            loss = hate_speech_loss + topic_loss\n",
    "\n",
    "        return loss, hate_speech_logits, topic_logits\n",
    "\n",
    "# Model initialization\n",
    "num_topics = len(topics)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskModel(model_name, num_topics).to(device)\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Optimizer and Scheduler\n",
    "# =======================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Training Setup\n",
    "# =======================\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Training and Evaluation\n",
    "# =======================\n",
    "def train_epoch(model, train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct_hate_speech, correct_topic = 0, 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, hate_speech_logits, topic_logits = model(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct_hate_speech += (hate_speech_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "        correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader), correct_hate_speech / len(train_dataset), correct_topic / len(train_dataset)\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss, correct_hate_speech, correct_topic = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, hate_speech_logits, topic_logits = model(**batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_hate_speech += (hate_speech_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "            correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct_hate_speech / len(val_dataset), correct_topic / len(val_dataset)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Train Model\n",
    "# =======================\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc_hate, train_acc_topic = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc_hate, val_acc_topic = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Hate Speech Acc: {train_acc_hate:.4f} | Topic Acc: {train_acc_topic:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Speech Acc: {val_acc_hate:.4f} | Topic Acc: {val_acc_topic:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# =======================\n",
    "# 8️⃣ Save Model\n",
    "# =======================\n",
    "from datetime import datetime\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define filename with timestamp\n",
    "model_path = f\"/kaggle/working/arabert_hate_speech_topics_better{timestamp}.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Model saved! ✅\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a28b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:06:22.061079Z",
     "iopub.status.busy": "2025-04-12T18:06:22.060816Z",
     "iopub.status.idle": "2025-04-12T18:31:51.375681Z",
     "shell.execute_reply": "2025-04-12T18:31:51.374061Z"
    },
    "papermill": {
     "duration": 1529.324452,
     "end_time": "2025-04-12T18:31:51.377331",
     "exception": true,
     "start_time": "2025-04-12T18:06:22.052879",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 1.7813 | Hate Acc: 0.6471 | Topic Acc: 0.4614\n",
      "Val Loss: 1.3166 | Hate Acc: 0.7140 | Topic Acc: 0.6639 | Hate F1: 0.7143\n",
      "Saved new best model\n",
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 1.1185 | Hate Acc: 0.7562 | Topic Acc: 0.7270\n",
      "Val Loss: 1.0511 | Hate Acc: 0.7677 | Topic Acc: 0.7580 | Hate F1: 0.7678\n",
      "Saved new best model\n",
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.7743 | Hate Acc: 0.8270 | Topic Acc: 0.8250\n",
      "Val Loss: 1.0929 | Hate Acc: 0.7633 | Topic Acc: 0.7692 | Hate F1: 0.7636\n",
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.5056 | Hate Acc: 0.8927 | Topic Acc: 0.8948\n",
      "Val Loss: 1.1659 | Hate Acc: 0.7618 | Topic Acc: 0.7640 | Hate F1: 0.7616\n",
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.3102 | Hate Acc: 0.9422 | Topic Acc: 0.9410\n",
      "Val Loss: 1.3614 | Hate Acc: 0.7588 | Topic Acc: 0.7558 | Hate F1: 0.7588\n",
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.1782 | Hate Acc: 0.9694 | Topic Acc: 0.9688\n",
      "Val Loss: 1.4597 | Hate Acc: 0.7491 | Topic Acc: 0.7797 | Hate F1: 0.7490\n",
      "\n",
      "Early stopping after 6 epochs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-aa77c3e853db>:344: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "\n",
      "Hate Speech Performance:\n",
      "Accuracy: 0.7612\n",
      "F1 Score: 0.7614\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aa77c3e853db>\u001b[0m in \u001b[0;36m<cell line: 401>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 Score: {test_results['hate_speech']['f1']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClassification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m print(classification_report(\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0mtest_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hate_speech'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No Hate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'support'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mtest_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hate_speech'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'support'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'int'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Enhanced Data Loading and Preprocessing\n",
    "# =======================\n",
    "def load_and_preprocess_data(file_path: str) -> Tuple:\n",
    "    \"\"\"Load and preprocess data with enhanced validation\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Validate data structure\n",
    "        required_columns = {'processed_comment', 'Hate speech', 'Topic'}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Missing required columns. Needed: {required_columns}\")\n",
    "        \n",
    "        # Enhanced label processing\n",
    "        df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "        \n",
    "        # Robust topic encoding\n",
    "        topics = df[\"Topic\"].unique()\n",
    "        topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "        df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "        \n",
    "        # Stratified split with validation\n",
    "        train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "            df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], \n",
    "            test_size=0.2, random_state=42, stratify=df[[\"Hate speech\", \"Topic\"]]\n",
    "        )\n",
    "        \n",
    "        val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "            temp_texts, temp_labels, temp_topics, \n",
    "            test_size=0.5, random_state=42, stratify=temp_labels\n",
    "        )\n",
    "        \n",
    "        return (train_texts, train_labels, train_topics, \n",
    "                val_texts, val_labels, val_topics,\n",
    "                test_texts, test_labels, test_topics,\n",
    "                len(topics))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "(train_texts, train_labels, train_topics, \n",
    " val_texts, val_labels, val_topics,\n",
    " test_texts, test_labels, test_topics,\n",
    " num_topics) = load_and_preprocess_data(file_path)\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Enhanced Tokenization\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_texts(texts: pd.Series) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Tokenize texts with enhanced settings\"\"\"\n",
    "    return tokenizer(\n",
    "        texts.tolist(),  # Convert to list for better performance\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False  # Not needed for AraBERT\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Enhanced Dataset Class\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings: Dict[str, torch.Tensor], \n",
    "                 hate_speech_labels: pd.Series, \n",
    "                 topic_labels: pd.Series):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels.values  # Convert to numpy for faster access\n",
    "        self.topic_labels = topic_labels.values\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx].clone(),\n",
    "            'attention_mask': self.encodings['attention_mask'][idx].clone(),\n",
    "            'hate_speech_labels': torch.tensor(self.hate_speech_labels[idx], dtype=torch.long),\n",
    "            'topic_labels': torch.tensor(self.topic_labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets with validation\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "# Enhanced DataLoaders with optimized settings\n",
    "batch_size = 32  # Increased batch size for better GPU utilization\n",
    "num_workers = 4 if torch.cuda.is_available() else 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ Advanced Hybrid Model Architecture\n",
    "# =======================\n",
    "class EnhancedHybridModel(nn.Module):\n",
    "    def __init__(self, model_name: str, num_topics: int):\n",
    "        super().__init__()\n",
    "        # BERT backbone\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.embedding_dim = self.bert.config.hidden_size\n",
    "        \n",
    "        # Enhanced CNN architecture with explicit padding\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(self.embedding_dim, 256, kernel_size=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(128, 64, kernel_size=4, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(64)\n",
    "        \n",
    "        # Classifiers with proper initialization\n",
    "        self.hate_classifier = self._init_classifier(64, 2)\n",
    "        self.topic_classifier = self._init_classifier(64, num_topics)\n",
    "        \n",
    "    def _init_classifier(self, in_features: int, out_features: int) -> nn.Module:\n",
    "        \"\"\"Initialize classifier with Xavier initialization\"\"\"\n",
    "        layer = nn.Linear(in_features, out_features)\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        nn.init.zeros_(layer.bias)\n",
    "        return layer\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, \n",
    "                attention_mask: torch.Tensor,\n",
    "                hate_speech_labels: torch.Tensor = None,\n",
    "                topic_labels: torch.Tensor = None) -> Tuple:\n",
    "        # BERT embeddings\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = bert_outputs.last_hidden_state.permute(0, 2, 1)  # (batch, emb_dim, seq_len)\n",
    "        \n",
    "        # CNN processing\n",
    "        x = embeddings\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, features)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_scores = F.softmax(self.attention(x), dim=1)\n",
    "        x = torch.sum(attention_scores * x, dim=1)\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Classification\n",
    "        hate_logits = self.hate_classifier(x)\n",
    "        topic_logits = self.topic_classifier(x)\n",
    "        \n",
    "        # Loss calculation if labels provided\n",
    "        loss = None\n",
    "        if hate_speech_labels is not None and topic_labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            hate_loss = loss_fn(hate_logits, hate_speech_labels)\n",
    "            topic_loss = loss_fn(topic_logits, topic_labels)\n",
    "            loss = hate_loss + 0.7 * topic_loss  # Weighted loss\n",
    "            \n",
    "        return loss, hate_logits, topic_logits\n",
    "\n",
    "# Initialize model with device placement\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnhancedHybridModel(model_name, num_topics).to(device)\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Optimized Training Setup\n",
    "# =======================\n",
    "# Optimizer with gradient clipping\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_epochs = 10  # Increased epochs with early stopping\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "warmup_steps = int(0.1 * num_training_steps)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Training monitoring\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1 = 0.0\n",
    "patience = 4\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Enhanced Training Loop\n",
    "# =======================\n",
    "def compute_metrics(logits: torch.Tensor, labels: torch.Tensor) -> Dict:\n",
    "    \"\"\"Compute multiple metrics for evaluation\"\"\"\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds, average='weighted')\n",
    "    }\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_hate_correct = 0\n",
    "    train_topic_correct = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, hate_logits, topic_logits = model(**batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        train_hate_correct += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "        train_topic_correct += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_hate_correct = 0\n",
    "    val_topic_correct = 0\n",
    "    all_hate_preds = []\n",
    "    all_hate_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, hate_logits, topic_logits = model(**batch)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            val_hate_correct += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "            val_topic_correct += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "            \n",
    "            # Store predictions for F1 calculation\n",
    "            all_hate_preds.extend(hate_logits.argmax(1).cpu().numpy())\n",
    "            all_hate_labels.extend(batch[\"hate_speech_labels\"].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "    train_hate_acc = train_hate_correct / len(train_dataset)\n",
    "    train_topic_acc = train_topic_correct / len(train_dataset)\n",
    "    \n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_hate_acc = val_hate_correct / len(val_dataset)\n",
    "    val_topic_acc = val_topic_correct / len(val_dataset)\n",
    "    val_hate_f1 = f1_score(all_hate_labels, all_hate_preds, average='weighted')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Hate Acc: {train_hate_acc:.4f} | Topic Acc: {train_topic_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Acc: {val_hate_acc:.4f} | Topic Acc: {val_topic_acc:.4f} | Hate F1: {val_hate_f1:.4f}\")\n",
    "    \n",
    "    # Early stopping and model checkpointing\n",
    "    if val_hate_f1 > best_val_f1:\n",
    "        best_val_f1 = val_hate_f1\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"Saved new best model\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"\\nEarly stopping after {epoch + 1} epochs!\")\n",
    "            break\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Comprehensive Evaluation\n",
    "# =======================\n",
    "def evaluate_model(model: nn.Module, data_loader: DataLoader) -> Dict:\n",
    "    \"\"\"Evaluate model on given data loader\"\"\"\n",
    "    model.eval()\n",
    "    all_hate_preds = []\n",
    "    all_hate_labels = []\n",
    "    all_topic_preds = []\n",
    "    all_topic_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            _, hate_logits, topic_logits = model(**batch)\n",
    "            \n",
    "            all_hate_preds.extend(hate_logits.argmax(1).cpu().numpy())\n",
    "            all_hate_labels.extend(batch[\"hate_speech_labels\"].cpu().numpy())\n",
    "            all_topic_preds.extend(topic_logits.argmax(1).cpu().numpy())\n",
    "            all_topic_labels.extend(batch[\"topic_labels\"].cpu().numpy())\n",
    "    \n",
    "    # Hate speech metrics\n",
    "    hate_metrics = {\n",
    "        'classification_report': classification_report(\n",
    "            all_hate_labels, all_hate_preds, \n",
    "            target_names=[\"No Hate\", \"Hate\"],\n",
    "            output_dict=True\n",
    "        ),\n",
    "        'accuracy': accuracy_score(all_hate_labels, all_hate_preds),\n",
    "        'f1': f1_score(all_hate_labels, all_hate_preds, average='weighted')\n",
    "    }\n",
    "    \n",
    "    # Topic metrics\n",
    "    topic_metrics = {\n",
    "        'classification_report': classification_report(\n",
    "            all_topic_labels, all_topic_preds,\n",
    "            output_dict=True\n",
    "        ),\n",
    "        'accuracy': accuracy_score(all_topic_labels, all_topic_preds),\n",
    "        'f1': f1_score(all_topic_labels, all_topic_preds, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'hate_speech': hate_metrics,\n",
    "        'topic': topic_metrics\n",
    "    }\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "test_results = evaluate_model(model, test_loader)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nHate Speech Performance:\")\n",
    "print(f\"Accuracy: {test_results['hate_speech']['accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {test_results['hate_speech']['f1']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['hate_speech']['classification_report']['No Hate']['support'],\n",
    "    test_results['hate_speech']['classification_report']['Hate']['support'],\n",
    "    target_names=[\"No Hate\", \"Hate\"]\n",
    "))\n",
    "\n",
    "print(\"\\nTopic Classification Performance:\")\n",
    "print(f\"Accuracy: {test_results['topic']['accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {test_results['topic']['f1']:.4f}\")\n",
    "\n",
    "# =======================\n",
    "# 8️⃣ Enhanced Model Saving\n",
    "# =======================\n",
    "def save_model_with_metadata(model: nn.Module, \n",
    "                           tokenizer: AutoTokenizer, \n",
    "                           metrics: Dict,\n",
    "                           config: Dict) -> None:\n",
    "    \"\"\"Save model with comprehensive metadata\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    model_path = f\"arabert_hate_speech_model_{timestamp}\"\n",
    "    \n",
    "    try:\n",
    "        # Save model weights\n",
    "        torch.save(model.state_dict(), f\"{model_path}.pth\")\n",
    "        \n",
    "        # Save tokenizer\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "        \n",
    "        # Save full configuration\n",
    "        full_config = {\n",
    "            \"model_config\": {\n",
    "                \"model_name\": model_name,\n",
    "                \"num_topics\": num_topics,\n",
    "                \"architecture\": str(model),\n",
    "                \"input_size\": 128  # Based on tokenizer max_length\n",
    "            },\n",
    "            \"training_config\": {\n",
    "                \"batch_size\": batch_size,\n",
    "                \"learning_rate\": 3e-5,\n",
    "                \"weight_decay\": 0.01,\n",
    "                \"epochs\": num_epochs\n",
    "            },\n",
    "            \"performance_metrics\": metrics\n",
    "        }\n",
    "        \n",
    "        with open(f\"{model_path}_config.json\", \"w\") as f:\n",
    "            json.dump(full_config, f, indent=4)\n",
    "        \n",
    "        print(f\"\\nModel successfully saved to {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving model: {str(e)}\")\n",
    "\n",
    "# Prepare metrics for saving\n",
    "final_metrics = {\n",
    "    'test_performance': test_results,\n",
    "    'best_validation': {\n",
    "        'loss': best_val_loss,\n",
    "        'hate_f1': best_val_f1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "save_model_with_metadata(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    metrics=final_metrics,\n",
    "    config={\n",
    "        'model_name': model_name,\n",
    "        'num_topics': num_topics\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7b74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:47:28.427978Z",
     "iopub.status.busy": "2025-04-05T17:47:28.427636Z",
     "iopub.status.idle": "2025-04-05T17:47:30.836043Z",
     "shell.execute_reply": "2025-04-05T17:47:30.834719Z",
     "shell.execute_reply.started": "2025-04-05T17:47:28.427951Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load Model & Tokenizer\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load dataset to dynamically extract topics (ensure this is the correct path)\n",
    "df = pd.read_excel(\"/kaggle/input/datasetes/Arabic.xlsx\")  # Update this with your actual file path\n",
    "\n",
    "# Dynamically extract topics and create a mapping\n",
    "topics = df[\"Topic\"].unique()  # Assuming 'Topic' column contains the topic names\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "\n",
    "# Define the same model structure\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hate_speech_classifier = nn.Linear(self.bert.config.hidden_size, 2)  # Hate speech (yes/no)\n",
    "        self.topic_classifier = nn.Linear(self.bert.config.hidden_size, num_topics)  # Topic classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
    "\n",
    "        hate_speech_logits = self.hate_speech_classifier(pooled_output)\n",
    "        topic_logits = self.topic_classifier(pooled_output)\n",
    "\n",
    "        return hate_speech_logits, topic_logits\n",
    "\n",
    "# Load model\n",
    "num_topics = len(topics)  # Dynamically adjust to the number of topics in the dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MultiTaskModel(model_name, num_topics).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/arabert_hate_speech_model_2025-04-05_17-34-23.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Function to Test Model\n",
    "# =======================\n",
    "def predict(text):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        hate_speech_logits, topic_logits = model(**inputs)\n",
    "\n",
    "    # Convert logits to predictions\n",
    "    hate_speech_pred = torch.argmax(hate_speech_logits, dim=1).item()\n",
    "    topic_pred = torch.argmax(topic_logits, dim=1).item()\n",
    "\n",
    "    # Map predictions to labels (using topic_to_id for dynamic mapping)\n",
    "    hate_speech_label = \"Hate Speech\" if hate_speech_pred == 1 else \"Not Hate Speech\"\n",
    "    topic_label = [k for k, v in topic_to_id.items() if v == topic_pred][0]  # Get the topic label from topic_to_id\n",
    "\n",
    "    return hate_speech_label, topic_label\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Test on New Text\n",
    "# =======================\n",
    "test_text = \"كلام تاع واحد لا علاقة بالعلم والله انه لدجال لعنه الله\"  # Change this text\n",
    "hs_label, topic_label = predict(test_text)\n",
    "\n",
    "print(f\"🔹 Input Text: {test_text}\")\n",
    "print(f\"✅ Hate Speech: {hs_label}\")\n",
    "print(f\"✅ Topic: {topic_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c650b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:16:00.246440Z",
     "iopub.status.busy": "2025-04-05T20:16:00.246172Z",
     "iopub.status.idle": "2025-04-05T20:27:49.056107Z",
     "shell.execute_reply": "2025-04-05T20:27:49.055095Z",
     "shell.execute_reply.started": "2025-04-05T20:16:00.246415Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Map labels\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# Split dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Tokenization\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Custom Dataset\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, hate_speech_labels, topic_labels):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels\n",
    "        self.topic_labels = topic_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels.iloc[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ CNN-BERT Hybrid Model\n",
    "# =======================\n",
    "class CNNBERTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics, num_filters=100, filter_sizes=[2,3,4]):\n",
    "        super(CNNBERTMultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.bert.config.hidden_size,\n",
    "                      out_channels=num_filters,\n",
    "                      kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc_shared = nn.Linear(num_filters * len(filter_sizes), 256)\n",
    "        self.hate_speech_classifier = nn.Linear(256, 2)\n",
    "        self.topic_classifier = nn.Linear(256, num_topics)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, hate_speech_labels=None, topic_labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, hidden_size, seq_len]\n",
    "\n",
    "        conv_outputs = [torch.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
    "        x = torch.cat(conv_outputs, dim=1)  # [batch_size, num_filters * len(filter_sizes)]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_shared(x)\n",
    "\n",
    "        hate_speech_logits = self.hate_speech_classifier(x)\n",
    "        topic_logits = self.topic_classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if hate_speech_labels is not None and topic_labels is not None:\n",
    "            hate_loss = nn.CrossEntropyLoss()(hate_speech_logits, hate_speech_labels)\n",
    "            topic_loss = nn.CrossEntropyLoss()(topic_logits, topic_labels)\n",
    "            loss = hate_loss + topic_loss\n",
    "\n",
    "        return loss, hate_speech_logits, topic_logits\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Train & Eval Functions\n",
    "# =======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_topics = len(topics)\n",
    "model = CNNBERTMultiTaskModel(model_name, num_topics).to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct_hate, correct_topic = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, hate_logits, topic_logits = model(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct_hate += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "        correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct_hate / len(loader.dataset), correct_topic / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct_hate, correct_topic = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, hate_logits, topic_logits = model(**batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_hate += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "            correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct_hate / len(loader.dataset), correct_topic / len(loader.dataset)\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Training Loop\n",
    "# =======================\n",
    "for epoch in range(3):\n",
    "    train_loss, train_acc_hate, train_acc_topic = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc_hate, val_acc_topic = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/3\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Hate Acc: {train_acc_hate:.4f} | Topic Acc: {train_acc_topic:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Acc: {val_acc_hate:.4f} | Topic Acc: {val_acc_topic:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Save the Model\n",
    "# =======================\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch.save(model.state_dict(), f\"/kaggle/working/cnn_bert_multitask_{timestamp}.pth\")\n",
    "print(\"✅ Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c3bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:29:08.420991Z",
     "iopub.status.busy": "2025-04-05T20:29:08.420656Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Map labels\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# Split dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Tokenization\n",
    "# =======================\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Custom Dataset\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, hate_speech_labels, topic_labels):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels\n",
    "        self.topic_labels = topic_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels.iloc[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ CNN-BERT Hybrid Model\n",
    "# =======================\n",
    "class CNNBERTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics, num_filters=100, filter_sizes=[2,3,4]):\n",
    "        super(CNNBERTMultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.bert.config.hidden_size,\n",
    "                      out_channels=num_filters,\n",
    "                      kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc_shared = nn.Linear(num_filters * len(filter_sizes), 256)\n",
    "        self.hate_speech_classifier = nn.Linear(256, 2)\n",
    "        self.topic_classifier = nn.Linear(256, num_topics)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, hate_speech_labels=None, topic_labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, hidden_size, seq_len]\n",
    "\n",
    "        conv_outputs = [torch.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
    "        x = torch.cat(conv_outputs, dim=1)  # [batch_size, num_filters * len(filter_sizes)]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_shared(x)\n",
    "\n",
    "        hate_speech_logits = self.hate_speech_classifier(x)\n",
    "        topic_logits = self.topic_classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if hate_speech_labels is not None and topic_labels is not None:\n",
    "            hate_loss = nn.CrossEntropyLoss()(hate_speech_logits, hate_speech_labels)\n",
    "            topic_loss = nn.CrossEntropyLoss()(topic_logits, topic_labels)\n",
    "            loss = hate_loss + topic_loss\n",
    "\n",
    "        return loss, hate_speech_logits, topic_logits\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Train & Eval Functions\n",
    "# =======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_topics = len(topics)\n",
    "model = CNNBERTMultiTaskModel(model_name, num_topics).to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct_hate, correct_topic = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, hate_logits, topic_logits = model(**batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct_hate += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "        correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct_hate / len(loader.dataset), correct_topic / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct_hate, correct_topic = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, hate_logits, topic_logits = model(**batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_hate += (hate_logits.argmax(1) == batch[\"hate_speech_labels\"]).sum().item()\n",
    "            correct_topic += (topic_logits.argmax(1) == batch[\"topic_labels\"]).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct_hate / len(loader.dataset), correct_topic / len(loader.dataset)\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Training Loop\n",
    "# =======================\n",
    "for epoch in range(3):\n",
    "    train_loss, train_acc_hate, train_acc_topic = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc_hate, val_acc_topic = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/3\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Hate Acc: {train_acc_hate:.4f} | Topic Acc: {train_acc_topic:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Acc: {val_acc_hate:.4f} | Topic Acc: {val_acc_topic:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Save the Model\n",
    "# =======================\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch.save(model.state_dict(), f\"/kaggle/working/cnn_bert_multitask_{timestamp}.pth\")\n",
    "print(\"✅ Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043dc4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T15:49:32.024756Z",
     "iopub.status.busy": "2025-04-12T15:49:32.024426Z",
     "iopub.status.idle": "2025-04-12T16:00:47.109309Z",
     "shell.execute_reply": "2025-04-12T16:00:47.108354Z",
     "shell.execute_reply.started": "2025-04-12T15:49:32.024718Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert labels to numeric values\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Encode topics as numbers\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# Split into train (80%), validation (10%), and test (10%)\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 2️⃣ Tokenization\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# 3️⃣ Custom Dataset Class\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, hate_speech_labels, topic_labels):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels\n",
    "        self.topic_labels = topic_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels.iloc[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Create datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# 4️⃣ Define Model\n",
    "# =======================\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_topics):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.hate_speech_classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.topic_classifier = nn.Linear(self.bert.config.hidden_size, num_topics)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        hate_speech_logits = self.hate_speech_classifier(pooled_output)\n",
    "        topic_logits = self.topic_classifier(pooled_output)\n",
    "        return hate_speech_logits, topic_logits\n",
    "\n",
    "# =======================\n",
    "# 5️⃣ Training Setup\n",
    "# =======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskModel(model_name, num_topics=len(topics)).to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# =======================\n",
    "# 6️⃣ Training Loop\n",
    "# =======================\n",
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        hate_speech_labels = batch[\"hate_speech_labels\"].to(device)\n",
    "        topic_labels = batch[\"topic_labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hate_speech_logits, topic_logits = model(input_ids, attention_mask)\n",
    "\n",
    "        loss_hate_speech = loss_fn(hate_speech_logits, hate_speech_labels)\n",
    "        loss_topic = loss_fn(topic_logits, topic_labels)\n",
    "        loss = loss_hate_speech + loss_topic\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# =======================\n",
    "# 7️⃣ Evaluation Function\n",
    "# =======================\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_hate_speech = 0\n",
    "    correct_topic = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            hate_speech_labels = batch[\"hate_speech_labels\"].to(device)\n",
    "            topic_labels = batch[\"topic_labels\"].to(device)\n",
    "\n",
    "            hate_speech_logits, topic_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            loss_hate_speech = loss_fn(hate_speech_logits, hate_speech_labels)\n",
    "            loss_topic = loss_fn(topic_logits, topic_labels)\n",
    "            loss = loss_hate_speech + loss_topic\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            hate_speech_preds = torch.argmax(hate_speech_logits, dim=1)\n",
    "            topic_preds = torch.argmax(topic_logits, dim=1)\n",
    "\n",
    "            correct_hate_speech += (hate_speech_preds == hate_speech_labels).sum().item()\n",
    "            correct_topic += (topic_preds == topic_labels).sum().item()\n",
    "            total_samples += hate_speech_labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    hate_speech_acc = correct_hate_speech / total_samples\n",
    "    topic_acc = correct_topic / total_samples\n",
    "\n",
    "    return avg_loss, hate_speech_acc, topic_acc\n",
    "\n",
    "# =======================\n",
    "# 8️⃣ Run Training & Evaluation\n",
    "# =======================\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train(model, train_loader)\n",
    "    val_loss, val_hate_speech_acc, val_topic_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Hate Speech Acc: {val_hate_speech_acc:.4f} | Topic Acc: {val_topic_acc:.4f}\")\n",
    "\n",
    "# =======================\n",
    "# 9️⃣ Final Test Evaluation\n",
    "# =======================\n",
    "test_loss, test_hate_speech_acc, test_topic_acc = evaluate(model, test_loader)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f} | Hate Speech Acc: {test_hate_speech_acc:.4f} | Topic Acc: {test_topic_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T16:05:15.505216Z",
     "iopub.status.busy": "2025-04-12T16:05:15.504866Z",
     "iopub.status.idle": "2025-04-12T16:05:29.863607Z",
     "shell.execute_reply": "2025-04-12T16:05:29.862414Z",
     "shell.execute_reply.started": "2025-04-12T16:05:15.505194Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nlpaug\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78786ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T17:02:19.499077Z",
     "iopub.status.busy": "2025-04-12T17:02:19.498693Z",
     "iopub.status.idle": "2025-04-12T17:31:40.294210Z",
     "shell.execute_reply": "2025-04-12T17:31:40.293405Z",
     "shell.execute_reply.started": "2025-04-12T17:02:19.499050Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# =======================\n",
    "# 1️⃣ Load and Preprocess Data\n",
    "# =======================\n",
    "file_path = \"/kaggle/input/datasetes/Arabic.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert labels to numeric values\n",
    "df[\"Hate speech\"] = df[\"Hate speech\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Encode topics as numbers\n",
    "topics = df[\"Topic\"].unique()\n",
    "topic_to_id = {topic: i for i, topic in enumerate(topics)}\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_to_id)\n",
    "\n",
    "# =======================\n",
    "# Data Augmentation Function\n",
    "# =======================\n",
    "aug = naw.SynonymAug(aug_src='wordnet', lang='arb')\n",
    "\n",
    "def augment_text(text):\n",
    "    try:\n",
    "        return aug.augment(text)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Apply augmentation to positive class (Hate speech = 1)\n",
    "augmented_rows = df[df[\"Hate speech\"] == 1].copy()\n",
    "augmented_rows[\"processed_comment\"] = augmented_rows[\"processed_comment\"].apply(augment_text)\n",
    "\n",
    "# Concatenate the original data with augmented data\n",
    "df = pd.concat([df, augmented_rows]).reset_index(drop=True)\n",
    "\n",
    "# =======================\n",
    "# Split Data\n",
    "# =======================\n",
    "train_texts, temp_texts, train_labels, temp_labels, train_topics, temp_topics = train_test_split(\n",
    "    df[\"processed_comment\"], df[\"Hate speech\"], df[\"Topic\"], test_size=0.2, random_state=42, stratify=df[\"Hate speech\"]\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels, val_topics, test_topics = train_test_split(\n",
    "    temp_texts, temp_labels, temp_topics, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Tokenization\n",
    "# =======================\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n",
    "\n",
    "# =======================\n",
    "# Custom Dataset Class\n",
    "# =======================\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, encodings, hate_speech_labels, topic_labels):\n",
    "        self.encodings = encodings\n",
    "        self.hate_speech_labels = hate_speech_labels\n",
    "        self.topic_labels = topic_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hate_speech_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item[\"hate_speech_labels\"] = torch.tensor(self.hate_speech_labels.iloc[idx], dtype=torch.long)\n",
    "        item[\"topic_labels\"] = torch.tensor(self.topic_labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels, train_topics)\n",
    "val_dataset = HateSpeechDataset(val_encodings, val_labels, val_topics)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels, test_topics)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# =======================\n",
    "# Model Definition\n",
    "# =======================\n",
    "class HateSpeechClassifier(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(HateSpeechClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HateSpeechClassifier(model_name).to(device)\n",
    "\n",
    "# =======================\n",
    "# Training Setup\n",
    "# =======================\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "save_path = \"/kaggle/working/arabert_hate_speech_best.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# =======================\n",
    "# Training Loop with Early Stopping\n",
    "# =======================\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = loss_fn(outputs, batch[\"hate_speech_labels\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "            loss = loss_fn(outputs, batch[\"hate_speech_labels\"])\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Save best model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"✅ Model saved to {save_path}\")\n",
    "\n",
    "# =======================\n",
    "# Evaluation on Test Set\n",
    "# =======================\n",
    "model.load_state_dict(torch.load(save_path))  # Load best model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"hate_speech_labels\"].cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"📊 Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7039923,
     "sourceId": 11263230,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7040755,
     "sourceId": 11264312,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7124486,
     "sourceId": 11378994,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 291275,
     "modelInstanceId": 270287,
     "sourceId": 320464,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3556.467525,
   "end_time": "2025-04-12T18:31:55.045731",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T17:32:38.578206",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "024af60772dd4d86b70588a02c108eb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0ad12d234ddf42b8b21649d2decf7f7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9d199ad354924c06a8c667b7727a85d0",
        "IPY_MODEL_a4761561d5a44a20924cf99747c4642a",
        "IPY_MODEL_aab9c3199f3c4dac9072a862d92c3bdd"
       ],
       "layout": "IPY_MODEL_dcef62408f4a4860bd79d807393c8405",
       "tabbable": null,
       "tooltip": null
      }
     },
     "10d1455961014527bb506efc67773b2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d21ff7539154054805276c2af681403",
        "IPY_MODEL_7ca7d9ea2bae402cb89bf016fdfe0db7",
        "IPY_MODEL_7b4cb5ea220c4f26a8da48a2e9634a92"
       ],
       "layout": "IPY_MODEL_30b69db13b6742c79e15b4ca6ba99356",
       "tabbable": null,
       "tooltip": null
      }
     },
     "13dd46d0f6864a62a49616cab09a9cbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "157160d6bc3647b59467cda0fdefebf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "164eb3c280bf4b9baf29df24462c5b72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19c6e725229f477a9fddade61097e6dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c1e054e281240f1b7d14c55a8e60d92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_772583d8b6fd4dc290e3b984006f9d86",
        "IPY_MODEL_4392d08c88ec4da984e7e3d7c5f811e5",
        "IPY_MODEL_ee2fb577fe154c7e95c517cf98028338"
       ],
       "layout": "IPY_MODEL_eec026096980491d86ead42bff3f500e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "21f735c1bd1e43c699fd282daf8053a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "22dab00cdd39405a91b26003d92c72d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "23aeee43a4434982b83f9ee323a5e570": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "243e2eb3c1c146619762d0c632fa6d3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aab298bf43649b690fd17490d5502b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30b69db13b6742c79e15b4ca6ba99356": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32fefa6e75764b9d867b3cd00cbc4e5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "373558c553a0456ca8013983603319ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3812319e6c474f5ba093b7e8965d3cec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d21ff7539154054805276c2af681403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6ba7543514044263a46375bb3e6b7cc9",
       "placeholder": "​",
       "style": "IPY_MODEL_d9701df90744408eb85c7261a766ac52",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "3d647037783e4d9ea25095c13a30cd96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23aeee43a4434982b83f9ee323a5e570",
       "max": 824793.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_024af60772dd4d86b70588a02c108eb0",
       "tabbable": null,
       "tooltip": null,
       "value": 824793.0
      }
     },
     "4392d08c88ec4da984e7e3d7c5f811e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_782b36adbfe34de7aca7d14cf21c3e39",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_373558c553a0456ca8013983603319ee",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "50b8086739194e11863a8d7656eae0ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50ba16444bc04ac49993f8d6581f024d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "522a23bd618d4008ae5e4bef01df7672": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "523dc84fa7794aa8b6c970ca9ec0edba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "526e41a8cf3848aeb55e880d40e150b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "598b42e7d1c44ba6a13dae6d92b09fb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5efef121fb9c41259eae4e05de5c83b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ba7543514044263a46375bb3e6b7cc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ce4bcde23ed4f56b6020f9377ed8885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6cf6768361934894892da2aac1c19cc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a78f2013b3864c77b4827664908b728b",
        "IPY_MODEL_3d647037783e4d9ea25095c13a30cd96",
        "IPY_MODEL_f6affb05b950409d8cbd5fd5ade7a2de"
       ],
       "layout": "IPY_MODEL_76a00ad8e28546cea484bfdcd2effe86",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6eb57ccc5863495191fdcfc501e66496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76a00ad8e28546cea484bfdcd2effe86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "772583d8b6fd4dc290e3b984006f9d86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5efef121fb9c41259eae4e05de5c83b4",
       "placeholder": "​",
       "style": "IPY_MODEL_50ba16444bc04ac49993f8d6581f024d",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "782b36adbfe34de7aca7d14cf21c3e39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79e55867f98e48a6a1953a05baf66845": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b5a8ff99134744a19d6f5b264fecfac1",
        "IPY_MODEL_8f9f2acc083d47c0bce4e6e4ca82a0e4",
        "IPY_MODEL_93654b3298f14e56a6f288ad72e9d1b7"
       ],
       "layout": "IPY_MODEL_598b42e7d1c44ba6a13dae6d92b09fb8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7b4cb5ea220c4f26a8da48a2e9634a92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_902cc3d15118468287f66f728b3e7b5e",
       "placeholder": "​",
       "style": "IPY_MODEL_6eb57ccc5863495191fdcfc501e66496",
       "tabbable": null,
       "tooltip": null,
       "value": " 384/384 [00:00&lt;00:00, 37.2kB/s]"
      }
     },
     "7ca7d9ea2bae402cb89bf016fdfe0db7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_164eb3c280bf4b9baf29df24462c5b72",
       "max": 384.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_959ba47e2cd942c1b8ea34b408e4fd69",
       "tabbable": null,
       "tooltip": null,
       "value": 384.0
      }
     },
     "8f9f2acc083d47c0bce4e6e4ca82a0e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_50b8086739194e11863a8d7656eae0ab",
       "max": 543432324.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b689f03136b945949b0d2ce881ea4a4e",
       "tabbable": null,
       "tooltip": null,
       "value": 543432324.0
      }
     },
     "902cc3d15118468287f66f728b3e7b5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93654b3298f14e56a6f288ad72e9d1b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_157160d6bc3647b59467cda0fdefebf8",
       "placeholder": "​",
       "style": "IPY_MODEL_97edde5279034210967a85f40d996ab3",
       "tabbable": null,
       "tooltip": null,
       "value": " 543M/543M [00:02&lt;00:00, 250MB/s]"
      }
     },
     "959ba47e2cd942c1b8ea34b408e4fd69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "97edde5279034210967a85f40d996ab3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d199ad354924c06a8c667b7727a85d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_523dc84fa7794aa8b6c970ca9ec0edba",
       "placeholder": "​",
       "style": "IPY_MODEL_13dd46d0f6864a62a49616cab09a9cbc",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "9d3ea8ebdc20415bbedcef6c174db864": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_526e41a8cf3848aeb55e880d40e150b8",
       "max": 381.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9fab9d9313e9429eba05e7c155207866",
       "tabbable": null,
       "tooltip": null,
       "value": 381.0
      }
     },
     "9fab9d9313e9429eba05e7c155207866": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a4761561d5a44a20924cf99747c4642a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab4e4e2c91fe40968d091cc85b9d3d4a",
       "max": 2642362.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ce4bcde23ed4f56b6020f9377ed8885",
       "tabbable": null,
       "tooltip": null,
       "value": 2642362.0
      }
     },
     "a59c56e2c052488e812142972fc9b1b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a658a9ef09674fd0b513d96c6f09c686",
       "placeholder": "​",
       "style": "IPY_MODEL_522a23bd618d4008ae5e4bef01df7672",
       "tabbable": null,
       "tooltip": null,
       "value": " 381/381 [00:00&lt;00:00, 36.0kB/s]"
      }
     },
     "a658a9ef09674fd0b513d96c6f09c686": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a78f2013b3864c77b4827664908b728b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_abc0aa5a498440f18e316352de182e6b",
       "placeholder": "​",
       "style": "IPY_MODEL_ac5b21b7677e45a4be381c030415e3bf",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "aab9c3199f3c4dac9072a862d92c3bdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b201096358c24b339661c6fa8fdf54e6",
       "placeholder": "​",
       "style": "IPY_MODEL_32fefa6e75764b9d867b3cd00cbc4e5b",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.64M/2.64M [00:00&lt;00:00, 26.4MB/s]"
      }
     },
     "ab4e4e2c91fe40968d091cc85b9d3d4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abc0aa5a498440f18e316352de182e6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac5b21b7677e45a4be381c030415e3bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b12ce45ec62d4a8a89dbe52fc703c8e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b201096358c24b339661c6fa8fdf54e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3d23b9918eb4e3f92a139812fab58b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e994c0442f6648488b0e20fd6de084bc",
        "IPY_MODEL_9d3ea8ebdc20415bbedcef6c174db864",
        "IPY_MODEL_a59c56e2c052488e812142972fc9b1b4"
       ],
       "layout": "IPY_MODEL_2aab298bf43649b690fd17490d5502b6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b5a8ff99134744a19d6f5b264fecfac1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_243e2eb3c1c146619762d0c632fa6d3f",
       "placeholder": "​",
       "style": "IPY_MODEL_be0d1d29b9074c368b5b061f456814c7",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b689f03136b945949b0d2ce881ea4a4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "be0d1d29b9074c368b5b061f456814c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6a0b7b26c814bd09e67178672a89e81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9701df90744408eb85c7261a766ac52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dcef62408f4a4860bd79d807393c8405": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e994c0442f6648488b0e20fd6de084bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b12ce45ec62d4a8a89dbe52fc703c8e3",
       "placeholder": "​",
       "style": "IPY_MODEL_21f735c1bd1e43c699fd282daf8053a6",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "ee2fb577fe154c7e95c517cf98028338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3812319e6c474f5ba093b7e8965d3cec",
       "placeholder": "​",
       "style": "IPY_MODEL_22dab00cdd39405a91b26003d92c72d0",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.2kB/s]"
      }
     },
     "eec026096980491d86ead42bff3f500e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6affb05b950409d8cbd5fd5ade7a2de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d6a0b7b26c814bd09e67178672a89e81",
       "placeholder": "​",
       "style": "IPY_MODEL_19c6e725229f477a9fddade61097e6dd",
       "tabbable": null,
       "tooltip": null,
       "value": " 825k/825k [00:00&lt;00:00, 13.7MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
